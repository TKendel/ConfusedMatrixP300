{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.signal import welch\n",
    "from scipy.stats import linregress\n",
    "\n",
    "# Step 1: Load EEG data from CSV file\n",
    "df = pd.read_csv('downsampled_final_125Hz.csv', usecols=lambda column: column not in ['Unnamed: 0.1', 'Unnamed: 0'])\n",
    "\n",
    "# Ensure data is sorted by participant_id, epoch, and timestep to avoid issues in feature extraction\n",
    "df = df.sort_values(by=['participant_id', 'epoch', 'timestep']).reset_index(drop=True)\n",
    "\n",
    "# Define EEG channel columns (assuming 'channel_1' to 'channel_8' are the relevant EEG channels)\n",
    "eeg_channels = [f'channel_{i}' for i in range(1, 9)]\n",
    "\n",
    "# Define sampling rate (Hz)\n",
    "fs = 125  # Assuming 125Hz as the sampling rate\n",
    "\n",
    "# Step 2: Define a function to extract features from each epoch\n",
    "def extract_features_by_epoch(df, eeg_channels, fs=125):\n",
    "    feature_list = []\n",
    "\n",
    "    # Group data by participant and epoch\n",
    "    grouped = df.groupby(['participant_id', 'epoch'])\n",
    "\n",
    "    for (participant_id, epoch), group in grouped:\n",
    "        features = {}\n",
    "\n",
    "        # Extract participant ID, epoch, and timestep range (from the first to the last timestep in the epoch)\n",
    "        features['participant_id'] = participant_id\n",
    "        features['epoch'] = epoch\n",
    "        features['timestep_start'] = group['timestep'].iloc[0]\n",
    "        features['timestep_end'] = group['timestep'].iloc[-1]\n",
    "\n",
    "        # 1. Time-Domain Features (Max, Min, Mean, Amplitude Range)\n",
    "        for channel in eeg_channels:\n",
    "            channel_values = group[channel].values\n",
    "            features[f'{channel}_max'] = np.max(channel_values)\n",
    "            features[f'{channel}_min'] = np.min(channel_values)\n",
    "            features[f'{channel}_mean'] = np.mean(channel_values)\n",
    "            features[f'{channel}_amplitude_range'] = np.max(channel_values) - np.min(channel_values)\n",
    "\n",
    "        # 2. Frequency-Domain Features (Alpha, Beta, Gamma Power using Welch method)\n",
    "        for channel in eeg_channels:\n",
    "            nperseg = min(len(group[channel].values), fs)\n",
    "            freqs, psd = welch(group[channel].values, fs=fs, nperseg=nperseg)\n",
    "            alpha_power = np.sum(psd[(freqs >= 8) & (freqs <= 12)])\n",
    "            beta_power = np.sum(psd[(freqs >= 13) & (freqs <= 30)])\n",
    "            gamma_power = np.sum(psd[(freqs >= 30) & (freqs <= 50)])\n",
    "            \n",
    "            features[f'{channel}_alpha_power'] = alpha_power\n",
    "            features[f'{channel}_beta_power'] = beta_power\n",
    "            features[f'{channel}_gamma_power'] = gamma_power\n",
    "\n",
    "        # 3. Fast Fourier Transform (FFT) Features\n",
    "        for channel in eeg_channels:\n",
    "            channel_values = group[channel].values\n",
    "            fft_values = np.fft.fft(channel_values)\n",
    "            fft_freqs = np.fft.fftfreq(len(fft_values), d=1/fs)\n",
    "\n",
    "            # Consider only the positive frequencies\n",
    "            positive_fft_values = fft_values[:len(fft_values) // 2]\n",
    "            positive_fft_freqs = fft_freqs[:len(fft_freqs) // 2]\n",
    "\n",
    "            # FFT features\n",
    "            total_power = np.sum(np.abs(positive_fft_values) ** 2)  # Total power in frequency domain\n",
    "            dominant_freq = positive_fft_freqs[np.argmax(np.abs(positive_fft_values))]  # Frequency with the maximum amplitude\n",
    "\n",
    "            features[f'{channel}_fft_total_power'] = total_power\n",
    "            features[f'{channel}_fft_dominant_frequency'] = dominant_freq\n",
    "\n",
    "        # 4. Signal Slope (Dynamic Feature)\n",
    "        for channel in eeg_channels:\n",
    "            slope, intercept, r_value, p_value, std_err = linregress(np.arange(len(channel_values)), channel_values)\n",
    "            features[f'{channel}_slope'] = slope\n",
    "\n",
    "        # 5. Inter-Channel Differences (Spatial Features)\n",
    "        for i in range(len(eeg_channels)):\n",
    "            for j in range(i + 1, len(eeg_channels)):\n",
    "                channel_i = group[eeg_channels[i]].values\n",
    "                channel_j = group[eeg_channels[j]].values\n",
    "                features[f'{eeg_channels[i]}_{eeg_channels[j]}_diff'] = np.mean(channel_i - channel_j)\n",
    "\n",
    "        # Add the trigger value (assuming we're taking the trigger from the last timestep in the epoch)\n",
    "        features['trigger'] = group['trigger'].iloc[-1]\n",
    "\n",
    "        # Append extracted features for this epoch\n",
    "        feature_list.append(features)\n",
    "\n",
    "    # Convert list of feature dicts into a DataFrame\n",
    "    return pd.DataFrame(feature_list)\n",
    "\n",
    "# Step 3: Apply feature extraction by epoch\n",
    "features_df = extract_features_by_epoch(df, eeg_channels, fs=fs)\n",
    "\n",
    "# Step 4: Save extracted features to a new CSV file\n",
    "features_df.to_csv('extracted_features.csv', index=False)\n",
    "\n",
    "# Step 5: Optional - print first few rows of the resulting features DataFrame to verify\n",
    "print(features_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| **Feature Name**                        | **Description**                                                                             |\n",
    "|-----------------------------------------|---------------------------------------------------------------------------------------------|\n",
    "| `participant_id`                        | Unique identifier for the participant, used to differentiate signal data from different individuals. |\n",
    "| `timestep_start`                        | The starting timestep of the sliding window, marking the beginning of the data segment.      |\n",
    "| `timestep_end`                          | The ending timestep of the sliding window, marking the end of the data segment.              |\n",
    "| `channel_X_max`                         | Maximum value of channel `X` within the current window, capturing the peak signal.          |\n",
    "| `channel_X_min`                         | Minimum value of channel `X` within the current window, capturing the lowest signal.        |\n",
    "| `channel_X_mean`                        | Mean value of channel `X` within the current window, representing the overall signal level. |\n",
    "| `channel_X_amplitude_range`             | Difference between the max and min values of channel `X`, showing the signal's amplitude range. |\n",
    "| `channel_X_alpha_power`                 | Power of the alpha band (8-12 Hz) for channel `X`, linked to relaxation and attention.      |\n",
    "| `channel_X_beta_power`                  | Power of the beta band (13-30 Hz) for channel `X`, associated with cognitive activity and focus. |\n",
    "| `channel_X_gamma_power`                 | Power of the gamma band (30-50 Hz) for channel `X`, related to high-level cognitive processes. |\n",
    "| `channel_X_fft_total_power`             | Total power in the frequency domain of channel `X`, representing the signal's overall energy. |\n",
    "| `channel_X_fft_dominant_frequency`      | Dominant frequency of channel `X`, indicating the most significant frequency component in the signal. |\n",
    "| `channel_X_slope`                       | Slope of the signal for channel `X` in the current window, indicating the trend (rising or falling) of the signal. |\n",
    "| `channel_X_channel_Y_diff`              | Average difference between signals of channel `X` and channel `Y`, showing inter-channel relationships. |\n",
    "| `trigger`                               | Event label or trigger value, indicating whether a specific event (e.g., P300) occurred within the window. |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   participant_id  timestep_start  timestep_end  channel_1_max  channel_1_min  \\\n",
      "0               5    59491.157032  59601.507948      14.575491     -15.777908   \n",
      "1               5    59491.157032  59601.507948      14.575491     -15.777908   \n",
      "2               5    59491.157032  59601.507948      14.575491     -15.777908   \n",
      "3               5    59491.157032  59601.507948      14.575491     -15.777908   \n",
      "4               5    59491.157032  59601.507948      14.575491     -15.777908   \n",
      "\n",
      "   channel_1_mean  channel_1_amplitude_range  channel_2_max  channel_2_min  \\\n",
      "0       -2.437404                  30.353399       3.202417     -18.177887   \n",
      "1       -2.437404                  30.353399       3.202417     -18.177887   \n",
      "2       -2.437404                  30.353399       3.202417     -18.177887   \n",
      "3       -2.437404                  30.353399       3.202417     -18.177887   \n",
      "4       -2.437404                  30.353399       3.202417     -18.177887   \n",
      "\n",
      "   channel_2_mean  ...  channel_4_channel_5_diff  channel_4_channel_6_diff  \\\n",
      "0       -6.904415  ...                  3.970347                 -0.934249   \n",
      "1       -6.904415  ...                  3.970347                 -0.934249   \n",
      "2       -6.904415  ...                  3.970347                 -0.934249   \n",
      "3       -6.904415  ...                  3.970347                 -0.934249   \n",
      "4       -6.904415  ...                  3.970347                 -0.934249   \n",
      "\n",
      "   channel_4_channel_7_diff  channel_4_channel_8_diff  \\\n",
      "0                  1.518475                   0.01667   \n",
      "1                  1.518475                   0.01667   \n",
      "2                  1.518475                   0.01667   \n",
      "3                  1.518475                   0.01667   \n",
      "4                  1.518475                   0.01667   \n",
      "\n",
      "   channel_5_channel_6_diff  channel_5_channel_7_diff  \\\n",
      "0                 -4.904597                 -2.451872   \n",
      "1                 -4.904597                 -2.451872   \n",
      "2                 -4.904597                 -2.451872   \n",
      "3                 -4.904597                 -2.451872   \n",
      "4                 -4.904597                 -2.451872   \n",
      "\n",
      "   channel_5_channel_8_diff  channel_6_channel_7_diff  \\\n",
      "0                 -3.953677                  2.452724   \n",
      "1                 -3.953677                  2.452724   \n",
      "2                 -3.953677                  2.452724   \n",
      "3                 -3.953677                  2.452724   \n",
      "4                 -3.953677                  2.452724   \n",
      "\n",
      "   channel_6_channel_8_diff  channel_7_channel_8_diff  \n",
      "0                   0.95092                 -1.501805  \n",
      "1                   0.95092                 -1.501805  \n",
      "2                   0.95092                 -1.501805  \n",
      "3                   0.95092                 -1.501805  \n",
      "4                   0.95092                 -1.501805  \n",
      "\n",
      "[5 rows x 70 columns]\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   participant_id  timestep_start  timestep_end  channel_1_max  channel_1_min  \\\n",
      "0               1     1303.574029   1414.492052      20.649432     -15.943325   \n",
      "1               1     1329.500000   1437.089260      20.649432     -15.943325   \n",
      "2               1     1350.325328   1454.524488      15.628820     -15.943325   \n",
      "3               1     1371.492052   1478.089260       8.848805     -15.943325   \n",
      "4               1     1394.089260   1498.448961       8.848805     -15.943325   \n",
      "\n",
      "   channel_1_mean  channel_1_amplitude_range  channel_2_max  channel_2_min  \\\n",
      "0       -1.006528                  36.592758      13.845616     -18.883505   \n",
      "1       -0.803566                  36.592758      13.845616     -15.320706   \n",
      "2       -4.242605                  31.572146      11.781255     -15.320706   \n",
      "3       -4.381019                  24.792130       6.261853     -15.320706   \n",
      "4       -3.913574                  24.792130      11.396095     -15.320706   \n",
      "\n",
      "   channel_2_mean  ...  channel_4_channel_6_diff  channel_4_channel_7_diff  \\\n",
      "0       -2.326962  ...                  5.096376                  3.396472   \n",
      "1       -0.501940  ...                  4.362270                  4.896450   \n",
      "2       -2.129392  ...                  3.087746                  4.753879   \n",
      "3       -2.636127  ...                  1.826296                  3.554654   \n",
      "4       -2.664202  ...                 -1.380390                 -0.253168   \n",
      "\n",
      "   channel_4_channel_8_diff  channel_5_channel_6_diff  \\\n",
      "0                  3.195517                  0.588841   \n",
      "1                  7.041899                 -2.431911   \n",
      "2                  4.974352                 -3.265149   \n",
      "3                  4.305716                 -3.766893   \n",
      "4                  0.596689                 -3.058630   \n",
      "\n",
      "   channel_5_channel_7_diff  channel_5_channel_8_diff  \\\n",
      "0                 -1.111063                 -1.312018   \n",
      "1                 -1.897730                  0.247719   \n",
      "2                 -1.599016                 -1.378543   \n",
      "3                 -2.038535                 -1.287473   \n",
      "4                 -1.931408                 -1.081551   \n",
      "\n",
      "   channel_6_channel_7_diff  channel_6_channel_8_diff  \\\n",
      "0                 -1.699904                 -1.900858   \n",
      "1                  0.534180                  2.679629   \n",
      "2                  1.666133                  1.886606   \n",
      "3                  1.728359                  2.479420   \n",
      "4                  1.127222                  1.977079   \n",
      "\n",
      "   channel_7_channel_8_diff  trigger  \n",
      "0                 -0.200955       -1  \n",
      "1                  2.145449       -1  \n",
      "2                  0.220473       -1  \n",
      "3                  0.751062       -1  \n",
      "4                  0.849857        1  \n",
      "\n",
      "[5 rows x 112 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.signal import welch\n",
    "from scipy.stats import linregress\n",
    "\n",
    "# Step 1: Load EEG data from CSV file\n",
    "df = pd.read_csv('downsampled_final_125Hz.csv', usecols=lambda column: column not in ['Unnamed: 0.1', 'Unnamed: 0'])\n",
    "\n",
    "df = df.sort_values(by=['participant_id', 'timestep']).reset_index(drop=True)\n",
    "\n",
    "# Define EEG channel columns (assuming 'channel_1' to 'channel_8' are the relevant EEG channels)\n",
    "eeg_channels = [f'channel_{i}' for i in range(1, 9)]\n",
    "\n",
    "# Define sampling rate (Hz)\n",
    "fs = 125  # Assuming 125Hz as the sampling rate\n",
    "\n",
    "# Define window size (e.g., 500ms) and step size (e.g., 100ms)\n",
    "window_size = int(0.5 * fs)  # 500ms window, which equals 62 samples at 125Hz\n",
    "step_size = int(0.1 * fs)    # 100ms step, equals 12 samples\n",
    "\n",
    "# Step 2: Define a function to extract features from each window\n",
    "def extract_features_with_sliding_window(df, eeg_channels, fs=125, window_size=62, step_size=12):\n",
    "    feature_list = []\n",
    "\n",
    "    # Sliding window over the entire dataset\n",
    "    for i in range(0, len(df) - window_size + 1, step_size):\n",
    "        window_df = df.iloc[i:i + window_size]  # Extract the current window of data\n",
    "        features = {}\n",
    "\n",
    "        # Extract participant ID and timestep (from the first row of the window)\n",
    "        features['participant_id'] = window_df['participant_id'].iloc[0]\n",
    "        features['timestep_start'] = window_df['timestep'].iloc[0]\n",
    "        features['timestep_end'] = window_df['timestep'].iloc[-1]\n",
    "\n",
    "        # 1. Time-Domain Features (Max, Min, Mean, Amplitude Range)\n",
    "        for channel in eeg_channels:\n",
    "            channel_values = window_df[channel].values\n",
    "            features[f'{channel}_max'] = np.max(channel_values)\n",
    "            features[f'{channel}_min'] = np.min(channel_values)\n",
    "            features[f'{channel}_mean'] = np.mean(channel_values)\n",
    "            features[f'{channel}_amplitude_range'] = np.max(channel_values) - np.min(channel_values)\n",
    "\n",
    "        # 2. Frequency-Domain Features (Alpha, Beta, Gamma Power using Welch method)\n",
    "        for channel in eeg_channels:\n",
    "            nperseg = min(len(window_df[channel].values), fs)\n",
    "            freqs, psd = welch(window_df[channel].values, fs=fs, nperseg=nperseg)\n",
    "            alpha_power = np.sum(psd[(freqs >= 8) & (freqs <= 12)])\n",
    "            beta_power = np.sum(psd[(freqs >= 13) & (freqs <= 30)])\n",
    "            gamma_power = np.sum(psd[(freqs >= 30) & (freqs <= 50)])\n",
    "            \n",
    "            features[f'{channel}_alpha_power'] = alpha_power\n",
    "            features[f'{channel}_beta_power'] = beta_power\n",
    "            features[f'{channel}_gamma_power'] = gamma_power\n",
    "        \n",
    "        # 3. Fast Fourier Transform (FFT) Features\n",
    "        for channel in eeg_channels:\n",
    "            channel_values = window_df[channel].values\n",
    "            fft_values = np.fft.fft(channel_values)\n",
    "            fft_freqs = np.fft.fftfreq(len(fft_values), d=1/fs)\n",
    "\n",
    "            # Consider only the positive frequencies\n",
    "            positive_fft_values = fft_values[:len(fft_values) // 2]\n",
    "            positive_fft_freqs = fft_freqs[:len(fft_freqs) // 2]\n",
    "\n",
    "            # FFT features\n",
    "            total_power = np.sum(np.abs(positive_fft_values) ** 2)  # Total power in frequency domain\n",
    "            dominant_freq = positive_fft_freqs[np.argmax(np.abs(positive_fft_values))]  # Frequency with the maximum amplitude\n",
    "\n",
    "            features[f'{channel}_fft_total_power'] = total_power\n",
    "            features[f'{channel}_fft_dominant_frequency'] = dominant_freq\n",
    "\n",
    "        # 4. Signal Slope (Dynamic Feature)\n",
    "        for channel in eeg_channels:\n",
    "            channel_values = window_df[channel].values\n",
    "            slope, intercept, r_value, p_value, std_err = linregress(np.arange(len(channel_values)), channel_values)\n",
    "            features[f'{channel}_slope'] = slope\n",
    "\n",
    "        # 5. Inter-Channel Differences (Spatial Features)\n",
    "        for i in range(len(eeg_channels)):\n",
    "            for j in range(i + 1, len(eeg_channels)):\n",
    "                channel_i = window_df[eeg_channels[i]].values\n",
    "                channel_j = window_df[eeg_channels[j]].values\n",
    "                features[f'{eeg_channels[i]}_{eeg_channels[j]}_diff'] = np.mean(channel_i - channel_j)\n",
    "\n",
    "        # Add the trigger value (assuming we're taking the trigger from the last timestep in the window)\n",
    "        features['trigger'] = window_df['trigger'].iloc[-1]\n",
    "\n",
    "        # Append extracted features for this window\n",
    "        feature_list.append(features)\n",
    "\n",
    "    # Convert list of feature dicts into a DataFrame\n",
    "    return pd.DataFrame(feature_list)\n",
    "\n",
    "# Step 3: Apply feature extraction with sliding window\n",
    "features_df = extract_features_with_sliding_window(df, eeg_channels, fs=fs, window_size=window_size, step_size=step_size)\n",
    "\n",
    "# Step 4: Save extracted features to a new CSV file\n",
    "features_df.to_csv('extracted_features_by_window.csv', index=False)\n",
    "\n",
    "# Step 5: Optional - print first few rows of the resulting features DataFrame to verify\n",
    "print(features_df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
